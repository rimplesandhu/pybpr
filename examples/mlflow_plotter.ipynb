{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Plotter Demo - visualize experiment results\n",
    "from pybpr.plotter import MLflowPlotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plotter with path to mlflow.db\n",
    "plotter = MLflowPlotter(tracking_uri=\"mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available experiments:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artifact_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>movielens</td>\n",
       "      <td>/kfs2/projects/zazzle/pybpr/examples/mlruns/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>movielens_pipeline</td>\n",
       "      <td>/kfs2/projects/zazzle/pybpr/examples/mlruns/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Default</td>\n",
       "      <td>/kfs2/projects/zazzle/pybpr/examples/mlruns/0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id                name  \\\n",
       "0             2           movielens   \n",
       "1             1  movielens_pipeline   \n",
       "2             0             Default   \n",
       "\n",
       "                               artifact_location  \n",
       "0  /kfs2/projects/zazzle/pybpr/examples/mlruns/2  \n",
       "1  /kfs2/projects/zazzle/pybpr/examples/mlruns/1  \n",
       "2  /kfs2/projects/zazzle/pybpr/examples/mlruns/0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all experiments\n",
    "experiments = plotter.get_experiments()\n",
    "print(\"Available experiments:\")\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs in 'movielens':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>status</th>\n",
       "      <th>start_time</th>\n",
       "      <th>model.n_latent</th>\n",
       "      <th>model.use_user_bias</th>\n",
       "      <th>model.use_item_bias</th>\n",
       "      <th>model.use_global_bias</th>\n",
       "      <th>model.dropout</th>\n",
       "      <th>model.activation</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>eval_every</th>\n",
       "      <th>eval_user_size</th>\n",
       "      <th>early_stopping_patience</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_auc_std</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_auc_std</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81642b1cf43a44fd9ca9b796ed20c374</td>\n",
       "      <td>ml-100k_indicator</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1770668156911</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.666797</td>\n",
       "      <td>0.208743</td>\n",
       "      <td>0.680158</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.147874</td>\n",
       "      <td>0.671942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ac256ff8812b4644bcf73c9f0750aee2</td>\n",
       "      <td>ml-100k_indicator</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1770667892912</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.577491</td>\n",
       "      <td>0.178970</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.576418</td>\n",
       "      <td>0.096190</td>\n",
       "      <td>0.671344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19b333aab6b54ab097bc60b81d4eb161</td>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1770667383603</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.600266</td>\n",
       "      <td>0.142910</td>\n",
       "      <td>0.673798</td>\n",
       "      <td>0.598103</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.672973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ae4d940f04d7b9493dfb22ca268ee</td>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1770667038972</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.549327</td>\n",
       "      <td>0.156271</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.545891</td>\n",
       "      <td>0.105948</td>\n",
       "      <td>0.689677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df3edd9ab59f45199c1fecfafaa0128e</td>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>1770666925260</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id           run_name    status  \\\n",
       "0  81642b1cf43a44fd9ca9b796ed20c374  ml-100k_indicator  FINISHED   \n",
       "1  ac256ff8812b4644bcf73c9f0750aee2  ml-100k_indicator  FINISHED   \n",
       "2  19b333aab6b54ab097bc60b81d4eb161   ml-100k_metadata  FINISHED   \n",
       "3  005ae4d940f04d7b9493dfb22ca268ee   ml-100k_metadata  FINISHED   \n",
       "4  df3edd9ab59f45199c1fecfafaa0128e   ml-100k_metadata    FAILED   \n",
       "\n",
       "      start_time model.n_latent model.use_user_bias model.use_item_bias  \\\n",
       "0  1770668156911             15                True                True   \n",
       "1  1770667892912             15                True                True   \n",
       "2  1770667383603             15                True                True   \n",
       "3  1770667038972             64                True                True   \n",
       "4  1770666925260             64                True                True   \n",
       "\n",
       "  model.use_global_bias model.dropout model.activation  ... batch_size  \\\n",
       "0                  True           0.0             None  ...        100   \n",
       "1                  True           0.0             None  ...        100   \n",
       "2                  True           0.0             None  ...        100   \n",
       "3                  True           0.0             None  ...        500   \n",
       "4                  True           0.0             None  ...        NaN   \n",
       "\n",
       "  eval_every eval_user_size early_stopping_patience  test_auc test_auc_std  \\\n",
       "0         10           None                    1000  0.666797     0.208743   \n",
       "1         10           None                    1000  0.577491     0.178970   \n",
       "2         10           None                    1000  0.600266     0.142910   \n",
       "3         10           None                    1000  0.549327     0.156271   \n",
       "4        NaN            NaN                     NaN       NaN          NaN   \n",
       "\n",
       "  test_loss train_auc train_auc_std train_loss  \n",
       "0  0.680158  0.696439      0.147874   0.671942  \n",
       "1  0.678100  0.576418      0.096190   0.671344  \n",
       "2  0.673798  0.598103      0.090908   0.672973  \n",
       "3  0.689900  0.545891      0.105948   0.689677  \n",
       "4       NaN       NaN           NaN        NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get runs for a specific experiment\n",
    "exp_name = \"movielens\"\n",
    "runs = plotter.get_runs(experiment_name=exp_name)\n",
    "print(f\"Runs in '{exp_name}':\")\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Summary (sorted by test_auc):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>status</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml-100k_indicator</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.666797</td>\n",
       "      <td>0.671942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.600266</td>\n",
       "      <td>0.672973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml-100k_indicator</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.577491</td>\n",
       "      <td>0.671344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.549327</td>\n",
       "      <td>0.689677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml-100k_metadata</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            run_name    status  test_auc  train_loss\n",
       "0  ml-100k_indicator  FINISHED  0.666797    0.671942\n",
       "2   ml-100k_metadata  FINISHED  0.600266    0.672973\n",
       "1  ml-100k_indicator  FINISHED  0.577491    0.671344\n",
       "3   ml-100k_metadata  FINISHED  0.549327    0.689677\n",
       "4   ml-100k_metadata    FAILED       NaN         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary table with final metrics\n",
    "summary = plotter.summary_table(\n",
    "    experiment_name=exp_name,\n",
    "    metrics=[\"test_auc\", \"train_loss\"],\n",
    "    params=[\"n_latent\", \"lr\"]\n",
    ")\n",
    "print(\"Run Summary (sorted by test_auc):\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MLflowPlotter.plot_single_run() got an unexpected keyword argument 'save_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fig = \u001b[43mplotter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_single_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m81642b1cf43a44fd9ca9b796ed20c374\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstd_width\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_std\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./single_run_plot.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m plt.show()\n",
      "\u001b[31mTypeError\u001b[39m: MLflowPlotter.plot_single_run() got an unexpected keyword argument 'save_path'"
     ]
    }
   ],
   "source": [
    "\n",
    "fig = plotter.plot_single_run(\n",
    "    run_id='81642b1cf43a44fd9ca9b796ed20c374',\n",
    "    figsize=(14, 5),\n",
    "    std_width=2.0,\n",
    "    show_std=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all runs with train_loss and test_auc side by side\n",
    "fig = plotter.plot_runs_comparison(\n",
    "    experiment_name=exp_name,\n",
    "    metrics=[\"train_loss\", \"test_auc\"],\n",
    "    figsize=(14, 5),\n",
    "    std_width=1.0,\n",
    "    show_std=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare runs with different std_width\n",
    "fig = plotter.plot_runs_comparison(\n",
    "    experiment_name=exp_name,\n",
    "    metrics=[\"train_loss\", \"test_auc\"],\n",
    "    figsize=(14, 5),\n",
    "    std_width=2.0,\n",
    "    show_std=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 3 runs by test_auc with std bands\n",
    "fig = plotter.plot_best_runs(\n",
    "    experiment_name=exp_name,\n",
    "    metric=\"test_auc\",\n",
    "    n_best=3,\n",
    "    plot_metrics=[\"train_loss\", \"test_auc\"],\n",
    "    figsize=(14, 5),\n",
    "    std_width=2.0,\n",
    "    show_std=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metric history for custom analysis\n",
    "if len(runs) > 0:\n",
    "    run_id = runs.iloc[0][\"run_id\"]\n",
    "    histories = plotter.get_run_metrics_history(\n",
    "        run_id=run_id,\n",
    "        metric_keys=[\"train_loss\", \"test_auc\"]\n",
    "    )\n",
    "    print(\"Train Loss history:\")\n",
    "    print(histories[\"train_loss\"].head())\n",
    "    print(\"\\nTest AUC history:\")\n",
    "    print(histories[\"test_auc\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze grid search experiment results\n",
    "grid_exp_name = \"example4_grid_search\"\n",
    "\n",
    "try:\n",
    "    grid_runs = plotter.get_runs(\n",
    "        experiment_name=grid_exp_name\n",
    "    )\n",
    "    print(f\"Grid search runs: {len(grid_runs)}\")\n",
    "    \n",
    "    # Create summary table\n",
    "    grid_summary = plotter.summary_table(\n",
    "        experiment_name=grid_exp_name,\n",
    "        metrics=[\"test_auc\", \"train_loss\"],\n",
    "        params=[\"n_latent\", \"lr\", \"loss_function\"]\n",
    "    )\n",
    "    print(\"\\nGrid search results:\")\n",
    "    display(grid_summary)\n",
    "    \n",
    "    # Plot comparison with std bands\n",
    "    fig = plotter.plot_runs_comparison(\n",
    "        experiment_name=grid_exp_name,\n",
    "        metrics=[\"train_loss\", \"test_auc\"],\n",
    "        figsize=(14, 5),\n",
    "        std_width=1.0,\n",
    "        show_std=True\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "except ValueError as e:\n",
    "    msg = f\"Grid search experiment not found: {e}\"\n",
    "    print(msg)\n",
    "    print(\"Run Example 4 from simple_pipeline_example.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save plot to file\n",
    "fig = plotter.plot_runs_comparison(\n",
    "    experiment_name=exp_name,\n",
    "    metrics=[\"train_loss\", \"test_auc\"],\n",
    "    figsize=(14, 5),\n",
    "    std_width=1.5,\n",
    "    show_std=True\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "fig.savefig(\n",
    "    \"experiment_comparison.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "print(\"Plot saved to experiment_comparison.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
