{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsandhu/Projects/rdi_hero/pybpr/.venv/lib/python3.14/site-packages/hero/services/data_repo.py:1811: SyntaxWarning: 'return' in a 'finally' block\n",
      "  return file_resource\n"
     ]
    }
   ],
   "source": [
    "import hero\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "seed = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hero ML Model Registry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/01/30 09:53:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/30 09:53:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/30 09:53:53 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: https://dev-hero.nrel.gov/ml-model-registry/api/v1/proxy/dev-recommender-system-app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hero client and get patched MLflow\n",
    "print(\"Initializing Hero ML Model Registry...\")\n",
    "hero_client = hero.HeroClient()\n",
    "model_registry = hero_client.MLModelRegistry()\n",
    "mlflow = model_registry.get_patched_mlflow()\n",
    "mlflow.set_tracking_uri(model_registry.get_tracking_uri())\n",
    "tracking_uri = model_registry.get_tracking_uri()\n",
    "print(f\"MLflow Tracking URI: {tracking_uri}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: [Demo] pybpr\n",
      "Experiment ID: 132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set experiment\n",
    "\n",
    "# try:\n",
    "#     experiment = mlflow.set_experiment(experiment_name=experiment_name)\n",
    "# except:\n",
    "#     experiment_id = mlflow.create_experiment(experiment_name)\n",
    "experiment_name = \"[Demo] pybpr\"\n",
    "experiment = model_registry.read_or_create_experiment(experiment_name)\n",
    "print(f\"Experiment: {experiment.name}\")\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.pyfunc import PythonModel\n",
    "from preprocess import preprocess\n",
    "\n",
    "\n",
    "class ModelWrapper(PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        processed_input = preprocess(model_input)\n",
    "        print(f\"Processed input: {processed_input}\")\n",
    "        print(f\"Model input: {model_input}\")\n",
    "        return self.model.predict(processed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tags and parameters for the experiment, these will be logged with the run\n",
    "# and can be used to filter and search runs.\n",
    "tags = {\n",
    "    \"Project\": \"MLOps platform tests\",\n",
    "    \"autologging\": \"false\"\n",
    "}\n",
    "params = {\n",
    "    \"random_state\": seed,\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"max_features\": 3\n",
    "}\n",
    "\n",
    "# Load the diabetes dataset and split it into training and test sets\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    db.data, db.target, random_state=seed)\n",
    "\n",
    "# Creates a hello world data file, this is just to show how to load/save data files\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "with open(\"data/data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"hello\": \"world\"}, f, indent=2)\n",
    "\n",
    "print('ready to define eval and train')\n",
    "\n",
    "# Evaluates the model's predictions against the true values\n",
    "\n",
    "\n",
    "def evaluate(y, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "    mae = mean_absolute_error(y, pred)\n",
    "    r2 = r2_score(y, pred)\n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }\n",
    "\n",
    "# Trains a model and logs it to MLflow\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    mlflow.start_run(experiment_id=experiment.experiment_id)\n",
    "    mlflow.log_artifacts(\"data\", artifact_path=\"states\")\n",
    "\n",
    "    run = mlflow.active_run()\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_input(\n",
    "        mlflow.data.from_numpy(X_train),\n",
    "        context='Train')\n",
    "    mlflow.log_input(\n",
    "        mlflow.data.from_numpy(X_test),\n",
    "        context='Eval')\n",
    "\n",
    "    # Create and train models.\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model to make predictions on the test dataset.\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(predictions)\n",
    "\n",
    "    metrics = evaluate(y_test, predictions)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(metrics)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_test, predictions)\n",
    "\n",
    "    # Log the model with a wrapper\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=f\"hero-example-{int(time.time())}\",\n",
    "        python_model=ModelWrapper(rf),\n",
    "        code_paths=[\"./preprocess.py\"],\n",
    "        signature=signature,\n",
    "        # requirements=\"requirements.txt\", # or specify custom requirements here\n",
    "    )\n",
    "\n",
    "    # Note: The standard sklearn model logging is commented out since we're using a wrapped model above (see mlflow.pyfunc.log_model).\n",
    "    # mlflow.sklearn.log_model(\n",
    "    #     rf,\n",
    "    #     \"model\",\n",
    "    #     signature=signature,\n",
    "    #     # requirements=\"requirements.txt\",\n",
    "    # )\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "    # Note: not all deps captured in the requirements.txt are automatically captured by mlflow.\n",
    "    # You may need to manually add deps from git or private registries using a command like this:\n",
    "    # mlflow.models.update_model_requirements(\n",
    "    #     model_uri=f\"runs:/{run.info.run_id}/model\",\n",
    "    #     operation=\"add\",\n",
    "    #     requirement_list=[\"hero@ git+https://github.nrel.gov/Hero/hero@v0.8.0\"],\n",
    "    # )\n",
    "    print(experiment)\n",
    "    # print experiment id\n",
    "    print(f\"Experiment_id: {experiment.experiment_id}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "\n",
    "    return run\n",
    "\n",
    "\n",
    "# Do the thing and get the resulting run\n",
    "run = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_registry.list_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = model_registry.get_tracking_uri()\n",
    "print(f\"Tracking URI: {uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = model_registry.list_experiments()\n",
    "print(f\"Experiments: {experiments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in experiments[0].items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created = model_registry.read_experiment(id=experiments[0][\"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry.create_experiment(name=\"temp_experiment_12345\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry.list_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
